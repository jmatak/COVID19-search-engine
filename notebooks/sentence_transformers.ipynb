{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5vUgopsW1ReA",
    "outputId": "11b26d2f-7c45-4290-f21a-0174204408f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla T4'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)\n",
    "# 'Tesla P100-PCIE-16GB' worked great for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2F97CrP4WSe"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INSTRUCTIONS:\n",
    "- upload data.py, util.py, settings.py(actually not used, but easier because of dependencies in the code), preprocessing.py in ./content \n",
    "  and edit them in a way relative paths work(when importing)\n",
    "- there is \"Mount Drive\" option if you don't want to manually upload many times\n",
    "- i managed to build an engine by creating corpus(DataFrame) of abstracts back in the python console locally, then serialize it \n",
    "  with pickle into abstracts.txt, upload it here in ./content and then use it along with paper_ids in query_engine.fit method\n",
    "- the rest is basically executing the code given here with possible minor tweaks\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "colab_type": "code",
    "id": "kXf3BQzry9hH",
    "outputId": "a38c39c1-0fb1-4e9a-ddf6-bf29d6f53fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/46/b7d6c37d92d1bd65319220beabe4df845434930e3f30e42d3cfaecb74dc4/sentence-transformers-0.2.6.1.tar.gz (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n",
      "\u001b[?25hCollecting transformers>=2.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\u001b[K     |████████████████████████████████| 573kB 15.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.38.0)\n",
      "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 12.9MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 55.1MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 56.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.8.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.8.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.8.0->sentence-transformers) (2.9)\n",
      "Requirement already satisfied: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.8.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->transformers>=2.8.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->transformers>=2.8.0->sentence-transformers) (2.8.1)\n",
      "Building wheels for collected packages: sentence-transformers, sacremoses\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.2.6.1-cp36-none-any.whl size=74031 sha256=124ce4d6fdf662aa13dfda1cc280ed8a75db3358f93ccd53e8d2c3df7d633f8a\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/fa/17/2b081a8cd8b0a86753fb0e9826b3cc19f0207062c0b2da7008\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=0141af82172dcf84ea2a70aac3f0dbd7b7242f77678dc3dd16736535a146f4f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sentence-transformers sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed sacremoses-0.0.43 sentence-transformers-0.2.6.1 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93Xeht7k1mEQ"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import models\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sv6nma8p1p6h"
   },
   "outputs": [],
   "source": [
    "def normalize(embeddings):\n",
    "        \"\"\"\n",
    "        Normalizes embeddings using L2 normalization.\n",
    "        Args:\n",
    "            embeddings: input embeddings matrix\n",
    "        Returns:\n",
    "            normalized embeddings\n",
    "        \"\"\"\n",
    "        # Calculation is different for matrices vs vectors\n",
    "        if len(embeddings.shape) > 1:\n",
    "            return embeddings / np.linalg.norm(embeddings, axis=1).reshape(-1, 1)\n",
    "\n",
    "        else:\n",
    "            return embeddings / np.linalg.norm(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Co0i4sZu14CY"
   },
   "outputs": [],
   "source": [
    "def BERT_sentence_embeddings(data, query=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        corpus: DataFrame containing information about paragraphs : paper_id, section, text\n",
    "        query: if True, import is one sentence - a query\n",
    "    Returns:\n",
    "        corpus embeddings: numpy array containing paragraph embeddings for each text paragraph in input\n",
    "        which is obtained by averaging over sentence embeddings(try #1 - until a better idea arrives (probably not so great))\n",
    "        -dimensions: n x 768 where n represents number of input paragraphs\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    {\n",
    "    reimers-2019-sentence-bert,\n",
    "    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n",
    "    author = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = \"11\",\n",
    "    year = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"http://arxiv.org/abs/1908.10084\",\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #pre-trained model on semantic text similarity task\n",
    "    model = SentenceTransformer('bert-base-nli-stsb-mean-tokens') \n",
    "    \n",
    "    if query:\n",
    "        return normalize(np.array(model.encode([data])).reshape(1,768))\n",
    "    \n",
    "    else:\n",
    "        text_paragraphs = [paragraph for paragraph in list(data['text'])]\n",
    "        n=len(text_paragraphs)\n",
    "        \n",
    "        corpus_embeddings=[]\n",
    "        for paragraph in text_paragraphs:\n",
    "            sentences = sent_tokenize(paragraph)\n",
    "            sent_embeddings = normalize(np.array(model.encode(sentences)).reshape(-1,768))#shape = no_of_sents_in_paragraph X 768\n",
    "            corpus_embeddings.append(np.mean(sent_embeddings,axis=0).reshape(1,768)) \n",
    "        \n",
    "        return normalize(np.array(corpus_embeddings).reshape(n,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rknHhIIo1-Nf"
   },
   "outputs": [],
   "source": [
    "emb1 = BERT_sentence_embeddings('What do we know about COVID-19 risk factors?', query=True)\n",
    "emb2 = BERT_sentence_embeddings('Do co-existing respiratory/viral infections make the virus more transmissible or virulent?', query=True)\n",
    "emb3 = BERT_sentence_embeddings('The text is small and will load quickly and easily fit into memory.', query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dB1slJUt2rMs",
    "outputId": "2ee55070-9326-4318-9362-d4e8ae810c2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3296918]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing sentence embeddings\n",
    "np.dot(emb1,emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lSfKg-v72uuZ",
    "outputId": "4e0a9698-f407-46d6-ba10-7804fa104809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01860103]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(emb1,emb3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BWRDi25w2xqc",
    "outputId": "0c1ff3cc-ea9c-4fbf-b390-b814bb0de428"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11308038]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(emb3,emb2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "xwcb0D2X5kJ_",
    "outputId": "f034b236-47aa-4376-ea1a-40ed31b75160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nZEx_6Kf3ld5"
   },
   "outputs": [],
   "source": [
    "from data import CovidDataLoader\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n9KqA4hD54vR"
   },
   "outputs": [],
   "source": [
    "class QueryEngine_BERT():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.corpus = None\n",
    "        self.ids = None\n",
    "\n",
    "    def fit(self, corpus, document_ids=None):\n",
    "        \"\"\"\n",
    "        Builds the query engine on the given corpus.\n",
    "\n",
    "        Args:\n",
    "            corpus: list of documents to build the model on\n",
    "            document_ids: optional, if given it will associate the given id's to each document given in the corpus\n",
    "        \"\"\"\n",
    "        self.ids = document_ids\n",
    "        self.corpus = [paragraph for paragraph in corpus['text']]\n",
    "        self.corpus_embeddings = BERT_sentence_embeddings(corpus, query=False)\n",
    "        \n",
    "    def __create_query_result(self, query, similarities, n):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            similarities: sparse matrix containing cosine similarities between the query vector and documents from corpus\n",
    "            n: number of most similar documents to include in the result\n",
    "\n",
    "        Returns:\n",
    "            pandas DataFrame containing query, document, similarity\n",
    "        \"\"\"\n",
    "\n",
    "        result = {\n",
    "            'query': query * len(similarities),\n",
    "            'text': self.corpus,\n",
    "            'sim': np.squeeze(similarities)\n",
    "        }\n",
    "        if self.ids:\n",
    "            result.update({'id': self.ids})\n",
    "\n",
    "        result = pd.DataFrame(result).sort_values(by='sim', ascending=False)[:n]\n",
    "\n",
    "        return result[result['sim'] > 0]\n",
    "\n",
    "    def run_query(self, query, n=5):\n",
    "        \"\"\"\n",
    "        Runs the given query, returns max n most similar documents from the corpus on which the model was build.\n",
    "\n",
    "        Args:\n",
    "            query: query to run\n",
    "            n: max number of results returned\n",
    "\n",
    "        Returns:\n",
    "            n(or less) most similar documents from the corpus on which the model was build\n",
    "        \"\"\"\n",
    "        if self.corpus is None:\n",
    "            raise AttributeError('Model not built yet, please call the fit method before running queries!')\n",
    "\n",
    "        assert type(query) == str\n",
    "            \n",
    "\n",
    "        query_embedding = BERT_sentence_embeddings(query, query=True)\n",
    "        similarities = np.dot(self.corpus_embeddings,query_embedding.T)  # TODO: check if this already sorts values\n",
    "        \n",
    "        return self.__create_query_result(query, similarities, n)\n",
    "\n",
    "    def save(self, dir_path, name):\n",
    "        \"\"\"\n",
    "        Serializes the object to file(name.dat) to the directory defined by the path.\n",
    "\n",
    "        Args:\n",
    "            dir_path: path of the directory to save the object to\n",
    "            name: name of the file without any extensions\n",
    "        \"\"\"\n",
    "        pickle_path = dir_path + name + '.dat'\n",
    "        print('Writing object to %s' % pickle_path)\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(pickle_path):\n",
    "        \"\"\"\n",
    "        Loads(de-serializes) QueryEngine object from the given path.\n",
    "\n",
    "        Args:\n",
    "            pickle_path: path to QueryEngine pickle\n",
    "\n",
    "        Returns:\n",
    "            QueryEngine object\n",
    "        \"\"\"\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            query_engine = pickle.load(f)\n",
    "            if type(query_engine) != QueryEngine_BERT:\n",
    "                raise ValueError('Path to non QueryEngine_BERT object!')\n",
    "            return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paM2onP26kwp"
   },
   "outputs": [],
   "source": [
    "with open(\"abstracts.txt\", \"rb\") as fp:\n",
    "  abstracts = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4SWjDBBFZaS",
    "outputId": "917780c5-ac4a-461c-b762-0e8dfb915c15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29306"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mr2eCWAFbwd"
   },
   "outputs": [],
   "source": [
    "paper_ids = [paper_id for paper_id in abstracts['paper_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "oIeCyU6lVoDo",
    "outputId": "763144c0-f737-459b-fbb5-ff5bed00a901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#execute this before the next cell \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "12VqiV5QF-1q",
    "outputId": "410cae74-3abd-4b07-ce00-f18e07c004e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing object to ./abstracts_query_engine_BERT.dat\n"
     ]
    }
   ],
   "source": [
    "query_engine = QueryEngine_BERT()\n",
    "query_engine.fit(abstracts, paper_ids)\n",
    "    \n",
    "query_engine.save('./', 'abstracts_query_engine_BERT') # i will save it and download locally, if ever in need of this exact version again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qv0I6BNPKzTu"
   },
   "outputs": [],
   "source": [
    "query_engine = QueryEngine_BERT.load('abstracts_query_engine_BERT.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TL0wmR6lMBDX"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_JiTyaFqLS3L",
    "outputId": "e55b847d-73e4-4312-f36f-8aa34e32a5ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row0_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row0_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row1_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row1_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row2_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row2_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row3_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row3_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row4_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row4_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row5_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row5_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row6_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row6_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row7_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row7_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row8_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row8_col1 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row9_col0 {\n",
       "            font-size:  7pt;\n",
       "        }    #T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row9_col1 {\n",
       "            font-size:  7pt;\n",
       "        }</style><table id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >text</th>        <th class=\"col_heading level0 col1\" >sim</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >25204</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row0_col0\" class=\"data row0 col0\" >Coronaviruses (CoVs), enveloped positive-sense RNA viruses, are characterized by club-like spikes that project from their surface, an unusually large RNA genome, and a unique replication strategy. Coronaviruses cause a variety of diseases in mammals and birds ranging from enteritis in cows and pigs and upper respiratory disease in chickens to potentially lethal human respiratory infections. Here we provide a brief introduction to coronaviruses discussing their replication and pathogenicity, and current prevention and treatment strategies. We also discuss the outbreaks of the highly pathogenic Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) and the recently identifi ed Middle Eastern Respiratory Syndrome Coronavirus (MERS-CoV). Coronavirus virions are spherical with diameters of approximately 125 nm as depicted in recent studies by cryo-electron tomography and cryo-electron microscopy [ 2 , 3 ]. The most prominent feature of coronaviruses is the club-shaped spike projections emanating from the surface of the virion. These spikes are a defi ning feature of the virion and give them the appearance of a solar corona, prompting the name, coronaviruses. Within the envelope of the virion is the nucleocapsid. Coronaviruses have helically symmetrical nucleocapsids, which is uncommon among positive-sense RNA viruses, but far more common for negative-sense RNA viruses. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.631149</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >12368</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Coronaviruses are etiologic agents of respiratory and enteric diseases in humans and in animals. In this study, a one-step real-time reverse transcriptionpolymerase chain reaction (RT-PCR) assay based on SYBR Green chemistry and degenerate primers was developed for the generic detection of coronaviruses. The primers, designed in the open reading frame 1b, enabled the detection of 32 animal coronaviruses including strains of canine coronavirus, feline coronavirus, transmissible gastroenteritis virus (TGEV), bovine coronavirus (BCoV), murine hepatitis virus (MHV) and infectious bronchitis virus (IBV). A specific amplification was also observed with the human coronaviruses (HCoV) HCoV-NL63, HCoV-OC43, HCoV-229E and severe acute respiratory syndrome coronavirus (SARS-CoV). The real-time RT-PCR detected down to 10 cRNA copies from TGEV, BCoV, SARS-CoV and IBV. In addition, the assay exhibited a high sensitivity and specificity on clinical samples from different animal species. The developed assay represents a potential tool for laboratory diagnostics and for detecting still uncharacterized coronaviruses. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.611510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >4371</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row2_col0\" class=\"data row2 col0\" >In 2012, a novel coronavirus, initially named as human coronavirus EMC (HCoV-EMC) but recently renamed as Middle East respiratory syndrome human coronavirus (MERS-CoV), was identified in patients who suffered severe acute respiratory infection and subsequent renal failure that resulted in death. Ongoing epidemiological investigations together with retrospective studies have found 61 laboratory-confirmed cases of infection with this novel coronavirus, including 34 deaths to date. This novel coronavirus is culturable and two complete genome sequences are now available. Furthermore, molecular detection and indirect immunofluorescence assay have been developed. The present paper summarises the limited recent advances of this novel human coronavirus, including its discovery, genomic characterisation and detection. HCoV-EMC, MERS-CoV, genomic characterisation, molecular detection Geng H Y, Tan W J. A novel human coronavirus: Middle East respiratory syndrome human coronavirus. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.609226</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >17116</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Severe acute respiratory syndrome (SARS) was first described during a 2002-2003 global outbreak of severe pneumonia associated with human deaths and person-toperson disease transmission. The etiologic agent was initially identified as a coronavirus by thin-section electron microscopic examination of a virus isolate. Virions were spherical, 78 nm in mean diameter, and composed of a helical nucleocapsid within an envelope with surface projections. We show that infection with the SARS-associated coronavirus resulted in distinct ultrastructural features: double-membrane vesicles, nucleocapsid inclusions, and large granular areas of cytoplasm. These three structures and the coronavirus particles were shown to be positive for viral proteins and RNA by using ultrastructural immunogold and in situ hybridization assays. In addition, ultrastructural examination of a bronchiolar lavage specimen from a SARS patient showed numerous coronavirus-infected cells with features similar to those in infected culture cells. Electron microscopic studies were critical in identifying the etiologic agent of the SARS outbreak and in guiding subsequent laboratory and epidemiologic investigations. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.600575</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >14400</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row4_col0\" class=\"data row4 col0\" >Despite years of research, the precise determinants of coronavirus replication and pathogenesis remain unidentified. What is known of the pathogenesis of the severe acute respiratory syndrome coronavirus (SARS-CoV) is limited, but clinical observations suggest that both viral-induced cytotoxicity and host immune-mediated destruction contribute to the severity of disease. This summary discusses recent advances in coronavirus research that will facilitate the identification of crucial molecular targets for the rational design of SARS therapeutics. When the SARS coronavirus came dramatically to attention as a fatal and potentially pandemic respiratory disease, the scientific response was swift and effective. The etiological agent was identified, the genome was cloned and sequenced, and large strides have been made in understanding key points in the viral life cycle, including recent identification of a functional host cell receptor and solution of the three-dimensional structure of the viral attachment protein. Much of this progress was possible only because a foundation of basic coronavirus biology existed. The Denison laboratory has been at the forefront of the small group of investigators who have dissected the basic features of coronaviruses. Denison has discovered critical mechanisms in the life cycle of the coronaviruses and is a key figure in the effective and urgent application of this knowledge to SARS. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.594483</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >13216</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row5_col0\" class=\"data row5 col0\" >Doughnut-shaped particles, 55-65 nm in diameter, were revealed by electron microscopy in the cisterns of the rough endoplasmic reticulum of cells from an active lesion in autopsied brain tissue from a multiple sclerosis patient. The morphology of the particles closely resembled that of coronaviruses. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.591290</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >24715</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Coronaviruses have been closely related with mankind for thousands of years. Communityacquired human coronaviruses have long been recognized to cause common cold. However, zoonotic coronaviruses are now becoming more a global concern with the discovery of highly pathogenic severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) coronaviruses causing severe respiratory diseases. Infections by these emerging human coronaviruses are characterized by less robust interferon production. Treatment of patients with recombinant interferon regimen promises beneficial outcomes, suggesting that compromised interferon expression might contribute at least partially to the severity of disease. The mechanisms by which coronaviruses evade host innate antiviral response are under intense investigations. This review focuses on the fierce arms race between host innate antiviral immunity and emerging human coronaviruses. Particularly, the host pathogen recognition receptors and the signal transduction pathways to mount an effective antiviral response against SARS and MERS coronavirus infection are discussed. On the other hand, the counter-measures evolved by SARS and MERS coronaviruses to circumvent host defense are also dissected. With a better understanding of the dynamic interaction between host and coronaviruses, it is hoped that insights on the pathogenesis of newly-identified highly pathogenic human coronaviruses and new strategies in antiviral development can be derived. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row6_col1\" class=\"data row6 col1\" >0.585042</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >24504</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row7_col0\" class=\"data row7 col0\" >Development of vaccination strategies for emerging pathogens are particularly challenging because of the sudden nature of the emergence of these viruses and the long process needed for traditional vaccine development. Therefore, there is a need for development of a rapid method of vaccine development that can respond to emerging pathogens in a short time frame. The emergence of severe acute respiratory syndrome coronavirus (SARS-CoV) in 2003 and Middle East respiratory syndrome (MERS-CoV) in late 2012 demonstrate the importance of coronaviruses as emerging pathogens. The spike glycoproteins of coronaviruses reside on the surface of the virion and are responsible for virus entry. The spike glycoprotein is the major immunodominant antigen of coronaviruses and has proven to be an excellent target for vaccine designs that seek to block coronavirus entry and promote antibody targeting of infected cells. Vaccination strategies for coronaviruses have involved live attenuated virus, recombinant viruses, non-replicative virus-like particles expressing coronavirus proteins or DNA plasmids expressing coronavirus genes. None of these strategies has progressed to an approved human coronavirus vaccine in the ten years since SARS-CoV emerged. Here we describe a novel method for generating MERS-CoV and SARS-CoV full-length spike nanoparticles, which in combination with adjuvants are able to produce high titer antibodies in mice. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0.581003</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >23009</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row8_col0\" class=\"data row8 col0\" >Human coronaviruses are known to be a common cause of respiratory infections in man. However, the diagnosis of human coronavirus infections is not carried out routinely, primarily because the isolation and propagation of these viruses in tissue culture is difficult and time consuming. The aim of this study was to evaluate the use of recombinant, bacterial expressed proteins in the serodiagnosis of coronavirus infections. Two proteins were examined: the human coronavirus 229E nucleocapsid protein (N), expressed as a fusion protein in the vector pUR and the coronavirus 229E surface glycoprotein (S), expressed as a fusion protein in the vector PROS. The recombinant proteins were used as antigens in Western blot (WB) assays to detect the 229E-specific IgG antibodies and the results were compared with a standard serological method, indirect immunofluorescence. Serum samples of 51 paediatric patients, suffering from acute respiratory illness, and 10 adults, voluntarily infected with human coronavirus, were tested. The semm samples of the adult group had coronavims-specific IgG antibodies in both test systems. In contrast, only 8/51 sera of the paediatric group were positive for coronavirus-specific IgG by both WB and IF and 20/51 sera were positive by WB, but not by IF. The overall incidence of human coronavims infections in the paediatric age group was 55% evaluated by WB analysis and 16% evaluated by IF. This study shows that recombinant human coronavirus 229E proteins are suitable reagents for the epidemiological screening of coronavirus 229E infections. 0166-0934/95/$09.50 0 1995 Elsevier Science B.V. All rights reserved SSDIO166-0934(95)00041-O </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row8_col1\" class=\"data row8 col1\" >0.578708</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >14512</th>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row9_col0\" class=\"data row9 col0\" >Development of vaccination strategies for emerging pathogens are particularly challenging because of the sudden nature of their emergence and the long process needed for traditional vaccine development. Therefore, there is a need for development of a rapid method of vaccine development that can respond to emerging pathogens in a short time frame. The emergence of severe acute respiratory syndrome coronavirus (SARS-CoV) in 2003 and Middle East Respiratory Syndrome Coronavirus (MERS-CoV) in late 2012 demonstrate the importance of coronaviruses as emerging pathogens. The spike glycoproteins of coronaviruses reside on the surface of the virion and are responsible for virus entry. The spike glycoprotein is the major immunodominant antigen of coronaviruses and has proven to be an excellent target for vaccine designs that seek to block coronavirus entry and promote antibody targeting of infected cells. Vaccination strategies for coronaviruses have involved live attenuated virus, recombinant viruses, nonreplicative virus-like particles expressing coronavirus proteins or DNA plasmids expressing coronavirus genes. None of these strategies has progressed to an approved human coronavirus vaccine in the ten years since SARS-CoV emerged. Here we describe a novel method for generating MERS-CoV and SARS-CoV full-length spike nanoparticles, which in combination with adjuvants are able to produce high titer antibodies in mice. </td>\n",
       "                        <td id=\"T_e8ffd2a6_8ff4_11ea_87a2_0242ac1c0002row9_col1\" class=\"data row9 col1\" >0.575677</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe76d382128>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.run_query('Physical science of the coronavirus',10)[['text','sim']].style.set_properties(**{'font-size': '7pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ff-0ZxjOPp2W"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: analogous with body_texts, possibly much longer time needed to build an engine :(\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sentence-transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
